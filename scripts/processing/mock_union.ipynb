{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tskit\n",
    "import pyslim\n",
    "import msprime\n",
    "import dendropy\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "import functools\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time(ts, dt):\n",
    "    '''\n",
    "    This function returns a tskit.TreeSequence in which `dt`\n",
    "    has been added to the times in all nodes.\n",
    "    '''\n",
    "    tables = ts.tables\n",
    "    nodes_dict = tables.nodes.asdict()\n",
    "    nodes_dict['time'] = nodes_dict['time'] + dt\n",
    "    tables.nodes.set_columns(**nodes_dict)\n",
    "    migrations_dict = tables.migrations.asdict()\n",
    "    migrations_dict['time'] = migrations_dict['time'] + dt\n",
    "    tables.migrations.set_columns(**migrations_dict)\n",
    "    mutations_dict = tables.mutations.asdict()\n",
    "    if not np.any(np.isnan(mutations_dict['time'])):\n",
    "        mutations_dict['time'] = mutations_dict['time'] + dt\n",
    "        tables.mutations.set_columns(**mutations_dict)\n",
    "    return pyslim.SlimTreeSequence.load_tables(tables)\n",
    "\n",
    "\n",
    "def match_nodes(tseqs, split_time):\n",
    "    \"\"\"\n",
    "    Given two SLiM tree sequences, returns a dictionary relating\n",
    "    the id in ts2 (key) to id in ts1 (item) for  node IDs in the\n",
    "    two tree sequences that refer to the same node. If split time\n",
    "    in ts2 (T2) is given, then only nodes before the split are\n",
    "    considered. Note the only check of equivalency is the slim_id\n",
    "    of the nodes.\n",
    "    \"\"\"\n",
    "    node_mapping = np.full(tseqs[1].num_nodes, tskit.NULL)\n",
    "    sids0 = np.array([n.metadata[\"slim_id\"] for n in tseqs[0].nodes()])\n",
    "    sids1 = np.array([n.metadata[\"slim_id\"] for n in tseqs[1].nodes()])\n",
    "    alive_before_split1 = tseqs[1].tables.nodes.time >= split_time\n",
    "    sorted_ids0 = np.argsort(sids0)\n",
    "    matches = np.searchsorted(\n",
    "        sids0,\n",
    "        sids1,\n",
    "        side='left',\n",
    "        sorter=sorted_ids0)\n",
    "    is_1in0 = np.isin(sids1, sids0)\n",
    "    both = np.logical_and(alive_before_split1, is_1in0)\n",
    "    node_mapping[both] = sorted_ids0[matches[both]]\n",
    "    return node_mapping\n",
    "\n",
    "def sub_metadata(tseqs):\n",
    "    \"\"\"\n",
    "    Work around current bug in `tskit.union`: subbing top-level metadata\n",
    "    so they match.\n",
    "    \"\"\"\n",
    "    tables0 = tseqs[0].tables\n",
    "    tables0.metadata = tseqs[1].tables.metadata\n",
    "    tseqs[0] = pyslim.SlimTreeSequence.load_tables(tables0)\n",
    "\n",
    "def msp_mutation_rate_map(intervals, total_rate, intervals_rate, length):\n",
    "    \"\"\"\n",
    "    Takes a `pd.DataFrame` with three columns (?, start, end), with 0-indexed [start, end) intervals.\n",
    "    Returns breaks and rates to use with `msprime.mutate`, in which the rate for `msprime` will be\n",
    "    `total_rate-intervals_rate` within the intervals.\n",
    "    \"\"\"\n",
    "    breaks = [0]\n",
    "    rates = []\n",
    "    for (i, c, start, end) in intervals.itertuples():\n",
    "        if start not in breaks:\n",
    "            breaks.append(start)\n",
    "            rates.append(total_rate)\n",
    "        breaks.append(end)\n",
    "        rates.append(total_rate-intervals_rate)\n",
    "    if not np.isclose(breaks[-1], length):\n",
    "        breaks.append(length)\n",
    "        rates.append(total_rate)\n",
    "    return msprime.RateMap(breaks, rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree(focal, edges, taxon_namespace, nodes = None):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of `dendropy.Node` objects from a `pandas.DataFrame`\n",
    "    with two columns: `edge` and `parent`, which specifies \n",
    "    the edge-parent relationships. Only nodes below focal are returned.\n",
    "    \"\"\"\n",
    "    if nodes == None:\n",
    "        nodes = {}\n",
    "    if not focal in nodes:\n",
    "        nodes[focal] = dendropy.Node(taxon=taxon_namespace.get_taxon(focal))\n",
    "    for i, row in edges.iterrows():\n",
    "        if row.parent == focal:\n",
    "            if not row.edge in nodes:\n",
    "                nodes[row.edge] = dendropy.Node(taxon=taxon_namespace.get_taxon(row.edge))\n",
    "            nodes[focal].add_child(nodes[row.edge])\n",
    "            nodes = subtree(row.edge, edges, taxon_namespace, nodes)\n",
    "    return nodes\n",
    "\n",
    "def build_tree_from_df(edges):\n",
    "    \"\"\"\n",
    "    Returns a `dendropy.Tree` from a `pandas.DataFrame` with edge-parent\n",
    "    relationships.\n",
    "    \"\"\"\n",
    "    root_name = edges.edge[edges.parent==\"\"][0]\n",
    "    taxon_namespace = dendropy.TaxonNamespace(edges.edge.values.tolist())\n",
    "    nodes = subtree(root_name, edges, taxon_namespace)\n",
    "    tree = dendropy.Tree(seed_node = nodes[root_name], taxon_namespace=taxon_namespace)\n",
    "    return(tree)\n",
    "\n",
    "def add_blen_from_meta(tree, meta, rand_id):\n",
    "    \"\"\"\n",
    "    `meta` is a `pandas.DataFrame` with columns `edge`, `rand_id`, `gens` and\n",
    "    `rescf`. This function adds branch lengths to the `dendropy.Tree` object \n",
    "    using the info in the `meta`.\n",
    "    \"\"\"\n",
    "    rep = '0' # all reps should be the have the sam blens anyway!\n",
    "    # traversing through tree -- annotating lengths\n",
    "    for node in tree.postorder_node_iter():\n",
    "        print(node.taxon.label)\n",
    "        subset = meta[(meta.edge==node.taxon.label) & (meta.rand_id == rand_id)]\n",
    "        assert subset.shape[0] == 1\n",
    "        n_gens = np.floor(subset.gens.values[0]/subset.rescf.values[0])\n",
    "        node.edge_length= n_gens\n",
    "        #print(node.edge_length)\n",
    "        #print(node.distance_from_tip())\n",
    "    tree.calc_node_root_distances(return_leaf_distances_only=False)\n",
    "    tree.calc_node_ages(ultrametricity_precision=False, is_force_max_age=True)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_tseqs(tree, rand_id, rep):\n",
    "    \"\"\"\n",
    "    Given a `dendropy.tree` object with annotated `edge_lengths`, a `rand_id` \n",
    "    identifier and a replicate number `rep`, this performs the \n",
    "    `tskit.TableCollection.union` of all leaves in the phylogenetic tree.\n",
    "    \"\"\"\n",
    "    in_tseqs = {}\n",
    "    for node in tree.postorder_node_iter(filter_fn = lambda node: node.is_internal()):\n",
    "        assert len(node.child_nodes()) == 2, \"Polytomies are not supported.\"\n",
    "        tseqs = []\n",
    "        pops = []\n",
    "        history_len = []\n",
    "        print(node.taxon.label, \"\\t\", node.age, sep=\"\")\n",
    "        for child in node.child_nodes():\n",
    "            print(\"\\t\"+child.taxon.label+\"\\t\"+str(child.root_distance)+\"\\t\"+str(child.age))\n",
    "            history_len.append(child.root_distance+child.age)\n",
    "            if child.is_leaf():\n",
    "                pops.append(child.taxon.label)\n",
    "                tseqs.append(pyslim.load(trees_path+child.taxon.label+\"_\"+rand_id+\"_rep\"+rep+\".trees\"))\n",
    "            else:\n",
    "                tseq, p = in_tseqs.pop(child.taxon.label)\n",
    "                tseqs.append(tseq)\n",
    "                pops += p\n",
    "                del tseq\n",
    "        #check if times need be shifted\n",
    "        print(f\"Before shift\\ttime 0: {tseqs[0].max_root_time}\\ttime 1: {tseqs[1].max_root_time}\")\n",
    "        if history_len[1] > history_len[0]:\n",
    "            tseqs[0] = add_time(tseqs[0], history_len[1]-history_len[0])\n",
    "        elif history_len[0] > history_len[1]:\n",
    "            tseqs[1] = add_time(tseqs[1], history_len[0]-history_len[1])\n",
    "        print(f\"After shift\\ttime 0: {tseqs[0].max_root_time}\\ttime 1: {tseqs[1].max_root_time}\")\n",
    "        node_mapping = match_nodes(tseqs, node.age)\n",
    "        sub_metadata(tseqs)\n",
    "        in_tseqs[node.taxon.label] = (tseqs[0].union(tseqs[1], node_mapping), pops)\n",
    "    assert len(in_tseqs) == 1\n",
    "    return in_tseqs[list(in_tseqs.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "\n",
    "# rand_id and rep\n",
    "rand_id = \"TZPNGS0UY29NGB3\"\n",
    "rep = \"0\"\n",
    "total_mut_rate = 1e-8\n",
    "ex_mut_rate = 0\n",
    "recapN = 10000\n",
    "\n",
    "## metadata paths\n",
    "edges_path = \"../../meta/edges_meta.tsv\"\n",
    "sims_sum_path = \"../../output/rand_id_params.tsv\"\n",
    "sims_full_path = \"../../output/sims_info.tsv\"\n",
    "sims_header_path = \"../../output/header_sims_info.tsv\"\n",
    "trees_path = \"../../output/\"\n",
    "rec_hap_path = f\"../../meta/maps/{rand_id}_recrate.hapmap\"\n",
    "ex_path = f\"../../meta/maps/{rand_id}_exons.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading metadata\n",
    "# edges contains all the edges and info about N and number of generations\n",
    "edges = pd.read_csv(edges_path,sep=\"\\t\")\n",
    "edges.parent= edges.parent.fillna(\"\")\n",
    "edges[\"edge\"] = edges[\"edge\"].str.replace('_','-')\n",
    "edges[\"parent\"] = edges[\"parent\"].str.replace('_','-')\n",
    "# sims_sum and sims_full relate rand_ids to simulation parameters\n",
    "sims_sum = pd.read_csv(sims_sum_path,sep=\"\\t\")\n",
    "sims_full= pd.read_csv(sims_full_path,sep=\"\\t\", header=None)\n",
    "header = pd.read_csv(\"../../output/header_sims_info.tsv\",sep=\"\\t\")\n",
    "sims_full.columns = header.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all output files and grouping by rand_id and rep\n",
    "tree_files = glob.glob(trees_path+\"*[0-9].trees\")\n",
    "pattern = f'{rand_id}_rep{rep}'\n",
    "n_matches = sum(1 for file in tree_files if pattern in file)\n",
    "# making sure we got all the files\n",
    "assert n_matches == edges.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bornean-orangutan\n",
      "sumatran-orangutan\n",
      "orangutans\n",
      "eastern-gorilla\n",
      "western-gorila\n",
      "gorilla\n",
      "humans\n",
      "bonobo\n",
      "nigerian-chimp\n",
      "western-chimp\n",
      "nigerian-western\n",
      "eastern-chimp\n",
      "central-chimp\n",
      "eastern-central\n",
      "chimps\n",
      "pan\n",
      "human-pan\n",
      "african-apes\n",
      "great-apes\n"
     ]
    }
   ],
   "source": [
    "# getting the phylo tree adn annotating with branch lengths,\n",
    "tree = build_tree_from_df(edges)\n",
    "tree = add_blen_from_meta(tree, sims_full, rand_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orangutans\t186.0\n",
      "\tbornean-orangutan\t4283.0\t0.0\n",
      "\tsumatran-orangutan\t4283.0\t0.0\n",
      "Before shift\ttime 0: 6784.0\ttime 1: 6784.0\n",
      "After shift\ttime 0: 6784.0\ttime 1: 6784.0\n",
      "gorilla\t78.0\n",
      "\teastern-gorilla\t5715.0\t0.0\n",
      "\twestern-gorila\t5715.0\t0.0\n",
      "Before shift\ttime 0: 8216.0\ttime 1: 8216.0\n",
      "After shift\ttime 0: 8216.0\ttime 1: 8216.0\n",
      "nigerian-western\t94.0\n",
      "\tnigerian-chimp\t5191.0\t0.0\n",
      "\twestern-chimp\t5191.0\t0.0\n",
      "Before shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "After shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "eastern-central\t70.0\n",
      "\teastern-chimp\t5191.0\t0.0\n",
      "\tcentral-chimp\t5191.0\t0.0\n",
      "Before shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "After shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "chimps\t171.0\n",
      "\tnigerian-western\t5097.0\t94.0\n",
      "\teastern-central\t5121.0\t70.0\n",
      "Before shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "After shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "pan\t348.0\n",
      "\tbonobo\t5191.0\t0.0\n",
      "\tchimps\t5020.0\t171.0\n",
      "Before shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "After shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "human-pan\t1505.0\n",
      "\thumans\t4984.0\t0.0\n",
      "\tpan\t4843.0\t348.0\n",
      "Before shift\ttime 0: 7485.0\ttime 1: 7692.0\n",
      "After shift\ttime 0: 7692.0\ttime 1: 7692.0\n",
      "african-apes\t2956.0\n",
      "\tgorilla\t5637.0\t78.0\n",
      "\thuman-pan\t3686.0\t1505.0\n",
      "Before shift\ttime 0: 8216.0\ttime 1: 7692.0\n",
      "After shift\ttime 0: 8216.0\ttime 1: 8216.0\n",
      "great-apes\t5715.0\n",
      "\torangutans\t4097.0\t186.0\n",
      "\tafrican-apes\t2759.0\t2956.0\n",
      "Before shift\ttime 0: 6784.0\ttime 1: 8216.0\n",
      "After shift\ttime 0: 8216.0\ttime 1: 8216.0\n",
      "7693\n",
      "8216\n"
     ]
    }
   ],
   "source": [
    "tsu,  pops = union_tseqs(tree,rand_id,rep)\n",
    "tsu = pyslim.load_tables(tsu.tables)\n",
    "print(tsu.slim_generation)\n",
    "assert tsu.max_root_time.is_integer()\n",
    "tsu = pyslim.annotate_defaults(tsu, tsu.metadata[\"SLiM\"][\"model_type\"], int(tsu.max_root_time))\n",
    "print(tsu.slim_generation)\n",
    "slim_gen = tsu.slim_generation\n",
    "# asserting within population coalescen\n",
    "assert len(set([tsu.node(u).population for t in tsu.trees() for u in t.roots])) == 1\n",
    "tsu.dump(f\"../../output/{rand_id}_rep{rep}.union.trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8216 117025.40151410378 0\n"
     ]
    }
   ],
   "source": [
    "recomb_map = msprime.RecombinationMap.read_hapmap(rec_hap_path)\n",
    "recap_tsu = tsu.recapitate(recombination_map=recomb_map, Ne=recapN)\n",
    "del tsu # too much ram\n",
    "print(slim_gen, recap_tsu.max_root_time, recap_tsu.num_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before mutate: 232\n",
      "Mutations added in the recapitation: 395\n",
      "Total mutations: 441\n"
     ]
    }
   ],
   "source": [
    "mut_map = msp_mutation_rate_map(exons, total_mut_rate, ex_mut_rate, int(recap_tsu.sequence_length))\n",
    "model_recap = msprime.SLiMMutationModel(type=3) # TODO: figure out the type number from the treeseq\n",
    "model_slim = msprime.SLiMMutationModel(type=4) # TODO: figure out the type number from the treeseq\n",
    "print(\"Before mutate:\", recap_tsu.num_mutations)\n",
    "recap_tsu = msprime.mutate(recap_tsu, end_time=slim_gen, model=model_recap, rate=total_mut_rate, keep=True)\n",
    "print(\"Mutations added in the recapitation:\", recap_tsu.num_mutations)\n",
    "recap_tsu = msprime.mutate(recap_tsu, start_time=slim_gen, model=model_slim, rate=mut_map, keep=True)\n",
    "print(\"Total mutations:\", recap_tsu.num_mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "win_size = 10**6\n",
    "seed = 8297\n",
    "rng = np.random.default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting contemporary samples\n",
    "# note the time of \"contemporary\" samples varies bc of differences in generation times\n",
    "pop_samples = [recap_tsu.samples(population_id=i+1) for i in range(len(pops))] \n",
    "contemp_time = [np.min(recap_tsu.tables.nodes.time[samples]) for samples in pop_samples]\n",
    "contemp_samples = [rng.choice(pop_samples[pid][recap_tsu.tables.nodes.time[pop_samples[pid]] == contemp_time[pid]], sample_size, replace=False)\n",
    "                                                        for pid in range(len(pop_samples))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowing\n",
    "windows = np.arange(start=0,stop=recap_tsu.sequence_length, step=win_size)\n",
    "if not np.isclose(recap_tsu.sequence_length, windows[-1], rtol=1e-12):\n",
    "    windows = np.append(windows, [recap_tsu.sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining indexes for all possible pairs (including diversity, i.e. i==j for (i,j))\n",
    "indexes = [(x, y) for x in range(len(pops)) for y in range(len(pops)) if x >= y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy = recap_tsu.divergence(sample_sets=contemp_samples, mode=\"site\", windows=windows, indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# half matrix + diagonal\n",
    "assert dxy.shape[1] == ((len(pops)**2 - len(pops))/2) + len(pops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([[pops[i],pops[j]] for i, j in indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"rand-id_{rand_id}_rep_{rep}_win-size_{win_size}_sample-size_{sample_size}.npz\", windows, dxy, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greatapes",
   "language": "python",
   "name": "greatapes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
