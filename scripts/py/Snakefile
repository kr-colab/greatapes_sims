import itertools
import pandas as pd
import numpy as np
import string
import random
import datetime as dt

def expand_grid(data_dict):
    """Create a dataframe from every combination of given values."""
    rows = itertools.product(*data_dict.values())
    return pd.DataFrame.from_records(rows, columns=data_dict.keys())

def id_generator(size=15, chars=string.ascii_uppercase + string.digits):
    return ''.join(random.choice(chars) for _ in range(size))

def get_par_string(row, col_names=["siminterval", "L", "recfile", "exonfile", "mu","delprop", "delcoef","posprop", "poscoef", "N", "gens"]):
    row_values = row.values.astype('str').tolist()
    return(' '.join(["-d "+col_names[i]+"=\\\""+row_values[i]+"\\\"" for i in                  range(len(col_names))]))

seed=101
random.seed(seed)

#these are the paths to all files/dir we will need
#this table contains info for all edges we will simulate
edges_path ="/home/murillor/projects/greatapes_sims/meta/edges_meta.tsv"
meta_path = "/home/murillor/projects/greatapes_sims/meta/sims/"
out_path = "../../output/"
#path to tsv file with recombination rates
rec_file = "/home/murillor/projects/greatapes_sims/meta/chr12_rec_rate_hg18.tsv"
rec_hap_file = "/home/murillor/projects/greatapes_sims/meta/chr12_rec_rate_hg18.hapmap"
#path to tsv with exon annotations
ex_file = "/home/murillor/projects/greatapes_sims/meta/chr12_exons_hg18.tsv"
overl_path = "/home/murillor/projects/greatapes_sims/scripts/py/overlay.py"
#path to slim recipe
recipe_path = "/home/murillor/projects/greatapes_sims/scripts/slim/recipe_sel_greatapes.slim"
nreps=2

#setting some parameters
L=100
sample_size=10
win_size=100000
total_mu = 1.66e-8
# proportions should be fractions
delprops = [0,0.10]
posprops = [0]
delcoefs = [0,-0.03]
poscoefs = [0]
sel_params = {"delprop":delprops, "delcoef":delcoefs, "posprop":posprops, "poscoef":poscoefs}
# cols with params
pars = ["siminterval", "L", "recfile", "exonfile", "mu","delprop", "delcoef", "posprop","poscoef", "N", "gens"]
# suck up params and hash them
edges_meta = pd.read_csv(edges_path,sep="\t")
edges_meta["edge"] = edges_meta["edge"].str.replace('_','-')
edges_meta["parent"] = edges_meta["parent"].str.replace('_','-')
#print(edges_meta)
edges_info = edges_meta[["edge","parent","N","gens"]]

edges_info.gens=10 #this is here just for testing purposes

#making a data frame that is going to hold all combinations of parameters
tmp=pd.DataFrame()
for i, row in edges_info.iterrows():
    row=row.to_dict()
    for key in row:
        row[key] = [row[key]]
    row.update(sel_params)
    tmp = pd.concat([tmp,expand_grid(row)])

#these boolean masks are here bc some parameter combs are nonsensical (e.g., no sim should have 0 proportion of positive mutations and pos coeff non-zero)
both_p = np.logical_and(tmp.posprop>0,tmp.poscoef > 0)
both_p_zero = np.logical_and(tmp.posprop==0,tmp.poscoef == 0)
both_d = np.logical_and(tmp.delprop>0,tmp.delcoef < 0)
both_d_zero = np.logical_and(tmp.delprop==0,tmp.delcoef == 0)
use_param_comb = np.logical_and(np.logical_or(both_p,both_p_zero),np.logical_or(both_d, both_d_zero))
tmp = tmp[use_param_comb]

#putting everything on our master data.frame (all params)
tmp["L"] = L
tmp["mu"] = (tmp.posprop+tmp.delprop)*total_mu
tmp["siminterval"] = np.where(tmp.N>500000,"500","")
tmp["exonfile"] = ex_file
tmp["recfile"] = rec_file
tmp["numid"] = tmp.groupby(["delprop","delcoef","posprop","poscoef"]).grouper.label_info
rands=np.array([id_generator() for i in range((tmp.numid.max()+1))])
tmp["rand_id"] = rands[tmp["numid"].tolist()]
tmp["outfile_pre"] = tmp.edge+"_"+tmp.rand_id
assert not tmp.outfile_pre.duplicated().any(), "one of the outfile names is duplicated"
tmp.outfile_pre=out_path+tmp.outfile_pre
tmp.reset_index(drop=True, inplace=True)
#finally assembling our parameter string which will be passed to the slim recipe
tmp["par_string"]=tmp[pars].apply(get_par_string, axis=1)

# writing tmp to file
today = dt.datetime.today().strftime('%m%d%Y')
tmp["date"] = today
tmp.to_csv("../../output/sims_info.tsv", sep="\t", header=False, index=False, mode="a")

# I'm getting the terminals bc not all trees are supposed to be overlayed with mutations and recapped
terminals=list(set(tmp.edge.tolist()) - set(tmp.parent.tolist()))
terminal_prefixes = np.array(tmp[tmp.edge.isin(terminals)].outfile_pre)

#dealing with replicates
replicated = np.repeat(terminal_prefixes, nreps)
pad=len(str(nreps))
uniqs=np.unique(replicated, return_counts=True)[1]
assert len(set(uniqs)) == 1, "Not all sims are being replicated equally."
rep_suf = np.tile(["rep"+str(i).zfill(pad) for i in range(uniqs[0])], len(uniqs))
all_replicates = [f"{x1}_{x2}.trees" for x1,x2 in zip(replicated,rep_suf)]

# overlay filenames
overl = [f"{x1}_{x2}_overl.trees" for x1,x2 in zip(replicated,rep_suf)]

# single stats filenames
single = [f"{x1}_{x2}_singlestats.tsv" for x1,x2 in zip(replicated, rep_suf)]

# this is here to make sure only treeseqs that are not inputs to the branch rule make it to be overlayed
ruleorder: root > branch > overlay > single_pop_stats

rule all:
    input:  single #+ tmp[tmp.edge.isin(terminals)].overl_out.tolist()

rule single_pop_stats:
    input: "../../output/{edge}_{rand_id}_rep{rep}_overl.trees"
    output: "../../output/{edge}_{rand_id}_rep{rep}_singlestats.tsv"
    params: win_size=win_size,  n=sample_size, L=L
    benchmark: "../../benchmarks/{edge}_{rand_id}_rep{rep}.singlestats.benchmark.txt"
    shell: "python stats_from_tree.py {input} {output} {wildcards.edge} {wildcards.rand_id} {wildcards.rep} {params.win_size} {params.L} {params.n}"

rule overlay:
    input: "../../output/{edge}_{rand_id}_rep{rep}.trees"
    params: mut_rate=total_mu, recapN=edges_meta[edges_meta.edge=="great-apes"].N.item(),
            rec_hap_path=rec_hap_file, ex_file_path=ex_file, sel_mut_rate=lambda wildcards: tmp[(tmp.edge==wildcards.edge) & (tmp.rand_id==wildcards.rand_id)].mu.item()
    output: "../../output/{edge}_{rand_id}_rep{rep}_overl.trees" 
    benchmark: "../../benchmarks/{edge}_{rand_id}_rep{rep}.overl.benchmark.txt"
    shell: "python overlay.py {input} {output} {params.mut_rate} {params.recapN} {params.rec_hap_path} {params.ex_file_path} {params.sel_mut_rate}"

rule root: 
    params: recipe = recipe_path, s = lambda wildcards: tmp[(tmp.edge=="great-apes") & (tmp.rand_id==wildcards.rand_id)].par_string.item()
    output: "../../output/great-apes_{rand_id}_rep{rep}.trees"
    benchmark: "../../benchmarks/great-apes_{rand_id}_rep{rep}.slim.benchmark.txt"
    shell:  "slim -m -t {params.s} -d outfile='\"{output}\"' {params.recipe}"

rule branch:
    input: lambda wildcards: "../../output/"+edges_info[edges_info.edge==wildcards.edge].parent.item()+"_"+wildcards.rand_id+"_rep"+wildcards.rep+".trees" 
    params: recipe=recipe_path,s=lambda wildcards: tmp[(tmp.edge==wildcards.edge) & (tmp.  rand_id==wildcards.rand_id)].par_string.item()
    wildcard_constraints: edge="(?!great-apes).*", rep="[0-9]+"
    output: "../../output/{edge}_{rand_id}_rep{rep}.trees"
    benchmark: "../../benchmarks/{edge}_{rand_id}_rep{rep}.slim.benchmark.txt"
    shell: "slim -m -t {params.s} -d path_population_tree='\"{input}\"' -d outfile='\"{output}\"' {params.recipe}"
